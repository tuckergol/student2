{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "comments: true\n",
    "layout: post\n",
    "title: ML Project - Individual Review Ticket\n",
    "description: Review Ticket for ML custom dataset.\n",
    "type: tangibles\n",
    "courses: { compsci: {week: 28} }\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "The topics for each of our (Aditya, Varun, Tucker) CPT projects collectively came to essentially stocks/business and cooking/food. So, we found a suitable dataset of ordered items from a bakery to combine those elements of business and food/cooking/baking, deciding that our ML model would determine a food order at the bakery (ex: \"Bread\", \"Coffee\", \"Pastry\", etc.) based on the other variables in the dataset (exact military time, general time: \"Afternoon/Morning\", and day of the week: \"Weekend/Weekday\").\n",
    "\n",
    "Because our dataset of ~20 thousand total rows/orders included nearly 1/4 \"Coffee\" as a food item, it was extremely common to get Coffee\"\" rather than any other item. Therefore, we made two separate Models, APIs, and frontend input fields to include both the normal (skewed by \"Coffee\") dataset/CSV file, and another identitical input field that simply used a different Model, API, and dataset and different datset/CSV file with \"Coffee\" filtered out. Screenshots below.\n",
    "\n",
    "### Project Screenshots\n",
    "\n",
    "<img src=\"https://github.com/tuckergol/student2/blob/main/images/ML1.png?raw=true\" width=\"470\" height=\"510\">\n",
    "\n",
    "<img src=\"https://github.com/tuckergol/student2/blob/main/images/ML2.png?raw=true\" width=\"470\" height=\"510\">\n",
    "\n",
    "<img src=\"https://github.com/tuckergol/student2/blob/main/images/ML3.png?raw=true\" width=\"470\" height=\"510\">\n",
    "\n",
    "<img src=\"https://github.com/tuckergol/student2/blob/main/images/ML4.png?raw=true\" width=\"470\" height=\"510\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backend Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code - Original API (food.py):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, jsonify, request\n",
    "from flask_restful import Resource, Api\n",
    "import pandas as pd\n",
    "from model.foods import food\n",
    "from flask import Flask, request, jsonify\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from flask_restful import Resource\n",
    "from flask import Blueprint, jsonify, request \n",
    "from flask_restful import Api, Resource\n",
    "\n",
    "food_api = Blueprint('food_api', __name__, url_prefix='/api/food')\n",
    "api = Api(food_api)\n",
    "\n",
    "class PredictItem(Resource):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = food()  \n",
    "    def post(self):\n",
    "        try:\n",
    "            # get JSON data from the request\n",
    "            payload = request.get_json()\n",
    "            print(payload)\n",
    "            foodModel = food.get_instance()\n",
    "            # Predict the item purchased from bakery\n",
    "            response = foodModel.predict(payload)\n",
    "            print(response)\n",
    "            \n",
    "            return jsonify(response)\n",
    "\n",
    "        except Exception as e:\n",
    "            return jsonify({'error': str(e)})\n",
    "        \n",
    "api.add_resource(PredictItem, '/predict')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code - Original Model (foods.py):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# Import the required libraries for the TitanicModel class\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "class food:\n",
    "    _instance = None\n",
    "    \"\"\" _init_(self): creates changeable instances and defines variables used for prediction through self.features and defines target variable to predict through self.target\"\"\"\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.dt = None\n",
    "        self.features = ['Hour', 'DayPart', 'DayType']  # Features for prediction\n",
    "        self.target = 'Items'  # Target variable to predict\n",
    "        self.data = pd.read_csv('filtered_data.csv')\n",
    "        \n",
    "    def _clean(self):\n",
    "        \"\"\"_clean(self) Converts data from the csv file into more readable form for ml. In this case, it reads the DayPart column and converts \"\"\"\n",
    "        self.data['DayPart'] = self.data['DayPart'].apply(lambda x: 1 if x == 'Morning' else 0)\n",
    "        self.data['DayType'] = self.data['DayType'].apply(lambda x: 1 if x == 'Weekend' else 0)\n",
    "        self.data['Hour'] = pd.to_datetime(self.data['Time'], format='%H:%M:%S').dt.hour\n",
    "        \n",
    "        \n",
    "    def _train(self):\n",
    "        X = self.data[self.features]  # Features\n",
    "        y = self.data[self.target]  # Target variable\n",
    "        \n",
    "        # Train a logistic regression model\n",
    "        self.model = LogisticRegression(max_iter=1000)\n",
    "        self.model.fit(X, y)\n",
    "        \n",
    "        # Train a decision tree classifier\n",
    "        self.dt = DecisionTreeClassifier()\n",
    "        self.dt.fit(X, y)\n",
    "        \n",
    "    @classmethod\n",
    "    def get_instance(cls):\n",
    "        \"\"\"Gets, and conditionally cleans and builds, the singleton instance of the Food model.\"\"\"\n",
    "        if cls._instance is None:\n",
    "            cls._instance = cls()\n",
    "            cls._instance._clean()\n",
    "            cls._instance._train()\n",
    "        return cls._instance\n",
    "    \n",
    "    def predict(self, payload):\n",
    "        \"\"\"Predict the item based on the given features. It is taken from the json input and is cleaned to match previous code so it can be used to predict\"\"\"\n",
    "        # Convert input to DataFrame\n",
    "        payload_df = pd.DataFrame(payload, index=[0])\n",
    "        # Convert categorical variables to binary\n",
    "        payload_df['DayPart'] = payload_df['DayPart'].apply(lambda x: 1 if x == 'Morning' else 0)\n",
    "        payload_df['DayType'] = payload_df['DayType'].apply(lambda x: 1 if x == 'Weekend' else 0)\n",
    "        payload_df['Hour'] = pd.to_datetime(payload_df['Time'], format='%H:%M:%S').dt.hour\n",
    "        #payload_df['Hour'] = pd.to_datetime(payload_df['Time']).dt.hour\n",
    "        # Predict item using the logistic regression model\n",
    "        #item = self.model.predict(payload_df)\n",
    "        item = self.model.predict(payload_df[self.features]) \n",
    "        #return {'item': item}\n",
    "        return {'item': item.tolist()} \n",
    "    def feature_weights(self):\n",
    "        \"\"\"Get the feature weights\n",
    "        The weights represent the relative importance of each feature in the prediction model.\n",
    "\n",
    "        Returns:\n",
    "            dictionary: contains each feature as a key and its weight of importance as a value\n",
    "        \"\"\"\n",
    "        # extract the feature importances from the decision tree model\n",
    "        importances = self.dt.feature_importances_\n",
    "        # return the feature importances as a dictionary, using dictionary comprehension\n",
    "        return {feature: importance for feature, importance in zip(self.features, importances)}\n",
    "def initfood():\n",
    "    food.get_instance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code/Data - Modifed/Added Segments in main.py (added model and API and init):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup APIs\n",
    "from api.covid import covid_api # Blueprint import api definition\n",
    "from api.joke import joke_api # Blueprint import api definition\n",
    "from api.user import user_api # Blueprint import api definition\n",
    "from api.player import player_api\n",
    "from api.titanic import titanic_api\n",
    "from api.food import food_api\n",
    "from api.bakery import bakery_api\n",
    "# database migrations\n",
    "from model.users import initUsers\n",
    "from model.players import initPlayers\n",
    "from model.foods import initfood \n",
    "from model.bakeries import initbakery\n",
    "\n",
    "# setup App pages\n",
    "from projects.projects import app_projects # Blueprint directory import projects definition\n",
    "\n",
    "\n",
    "# Initialize the SQLAlchemy object to work with the Flask app instance\n",
    "db.init_app(app)\n",
    "\n",
    "# register URIs\n",
    "app.register_blueprint(joke_api) # register api routes\n",
    "app.register_blueprint(covid_api) # register api routes\n",
    "app.register_blueprint(user_api) # register api routes\n",
    "app.register_blueprint(player_api)\n",
    "app.register_blueprint(app_projects) # register app pages\n",
    "app.register_blueprint(titanic_api)\n",
    "app.register_blueprint(food_api)\n",
    "app.register_blueprint(bakery_api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a command to generate data\n",
    "@custom_cli.command('generate_data')\n",
    "def generate_data():\n",
    "    initUsers()\n",
    "    initPlayers()\n",
    "    initfood()\n",
    "    initbakery()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
